<html>
<head>
<title>Project 2 -- thread library</title>
</head>
<body>
<h1>Project 2 -- thread library</h1>
Worth: 13 points<br>
Assigned: Tuesday, January 26, 2015<br>
Due: 11:59 pm, Wednesday, February 18, 2015

<h2 id="overview">1. Overview</h2>

<p>
This project will help you understand how threads and monitors are
implemented on uniprocessor and multiprocessor systems.  In this project,
you will implement a thread library similar to the one provided in
<a href="../project1/">Project 1</a>.

<h2 id="threadinterface">2. Interface to applications</h2>

<p>
This section describes the interface that your thread library and the
infrastructure provide to applications.  The interface consists of four
classes: <tt>cpu</tt>, <tt>thread</tt>, <tt>mutex</tt>, and <tt>cv</tt>,
which are declared in <a href=cpu.h><tt>cpu.h</tt></a>,
<a href=thread.h><tt>thread.h</tt></a>,
<a href=mutex.h><tt>mutex.h</tt></a>, and <a href=cv.h><tt>cv.h</tt></a> (do
not modify these files).  The interface is the same as the one provided <a
href="../project1/">Project 1</a>, except for the two differences described
below.  Because of these differences, Project 1 and 2 use different versions
of <a href=cpu.h><tt>cpu.h</tt></a>,
<a href=thread.h><tt>thread.h</tt></a>, and
<a href=libcpu.a><tt>libcpu.a</tt></a>.

<ul>

<li>
The <tt>cpu::boot</tt> function takes different parameters, which allow the
program to specify the number of CPUs and customize how interrupts are
generated.  One CPU will create the first thread,
which is initialized to call the function pointed to by
<tt>func</tt> with the argument <tt>arg</tt>.
<tt>async</tt>, <tt>sync</tt>, and <tt>random_seed</tt> control how timer
interrupts are generated.  As discussed in class, a timer interrupt
preempts the thread running on the current CPU and starts the next ready
thread.  If <tt>sync</tt> is true, timer interrupts will be triggered at
points in the program that are synchronized to executing instructions.  You
can generate different (but repeatable) patterns of synchronous timer
interrupt by changing <tt>random_seed</tt>.  If <tt>async</tt> is true, a
timer interrupt will be triggered on each CPU about once each millisecond.
A user program should
call <tt>cpu::boot</tt> exactly once (before calling any other thread
functions).  On success, <tt>cpu::boot</tt> does not return.

<pre>
    static void boot(unsigned int num_cpus, thread_startfunc_t func, void *arg, bool async, bool sync, int random_seed);
</pre>

<li>
The <tt>thread</tt> class provides an extra function
<tt>thread::yield()</tt>, which allows a thread to voluntarily give up the
CPU to the next runnable thread (if there is one).

<pre>
    static void yield();
</pre>

<p>
Note that <tt>thread::yield</tt> is a <tt>static</tt> member function and
is invoked on the <tt>thread</tt> class (not on an instance of the
<tt>thread</tt> class).

</ul>

<h2 id="threadlibrary">3. Thread library</h2>

You will write a thread library that implements the functions in
<a href=thread.h><tt>thread.h</tt></a>,
<a href=mutex.h><tt>mutex.h</tt></a>, and <a href=cv.h><tt>cv.h</tt></a>.
You will also implement the <tt>cpu::init</tt> function, which is called by
the infrastructure when it starts a CPU.

<h3 id="init">3.1. Initializing and identifying a CPU</h3>

<p>
Your thread library will provide a function <tt>cpu::init</tt> (this
is the only member of the <tt>cpu</tt> class that you will implement).
When the user program calls <tt>cpu::boot</tt>, the infrastructure
activates <tt>num_cpus</tt> CPUs and causes each CPU to execute
<tt>cpu::init</tt>.
One of the CPUs will call <tt>cpu::init</tt> with the arguments
(<tt>func</tt> and <tt>arg</tt>) passed to <tt>cpu::boot</tt>; the
other CPUs will call <tt>cpu::init</tt> with <tt>nullptr</tt> argument values.

<p>
<tt>cpu::init</tt> should cause the CPU to run threads as they become
available.  On success, <tt>cpu::init</tt> should not return to the caller;
on failure, <tt>cpu::init</tt> should throw an appropriate exception
(e.g., <tt>std::bad_alloc</tt> if it can't allocate memory).

<p>
If <tt>cpu::init</tt> is passed a function <tt>func</tt> that is not
<tt>nullptr</tt>, it should also create a thread that executes
<tt>func(arg)</tt>.

<p>
Your thread library may find it useful to identify which CPU a thread is
running on.  The function <tt>cpu::self</tt> returns a pointer to the
<tt>cpu</tt> object for the CPU this thread is running on.
Note that <tt>cpu::self</tt> is a <tt>static</tt> member function and is
invoked on the <tt>cpu</tt> class (not on an instance of the <tt>cpu</tt>
class).

<h3 id="createswap">3.2. Creating and swapping threads</h3>

<p>
You will be implementing your thread library on x86 PCs running the Linux
operating system.  Linux provides some library functions (<tt>getcontext</tt>,
<tt>makecontext</tt>, <tt>swapcontext</tt>) to help implement user-level
thread libraries.

<p>
Here's an example of how to use these functions to create a new thread
(read the Linux manual pages for details):

<hr>
<pre>
#include &lt;ucontext.h&gt;

/*
 * Initialize a context structure by copying the current thread's context.
 */
getcontext(ucontext_ptr);           // ucontext_ptr has type (ucontext_t *)

/*
 * Direct the new thread to use a different stack.  Your thread library
 * should allocate STACK_SIZE bytes for each thread's stack.
 */
char *stack = new char [STACK_SIZE];
ucontext_ptr->uc_stack.ss_sp = stack;
ucontext_ptr->uc_stack.ss_size = STACK_SIZE;
ucontext_ptr->uc_stack.ss_flags = 0;
ucontext_ptr->uc_link = nullptr;

/*
 * Direct the new thread to start by calling start(arg1, arg2).
 */
makecontext(ucontext_ptr, (void (*)()) start, 2, arg1, arg2);
</pre>
<hr>

<p>
Use <tt>swapcontext</tt> to save the context of the current thread and switch to the
context of another thread.

<h3 id="createswap">3.3. Thread, mutex, and condition variable lifetimes</h3>

<p>
This section describes two subtle points related to lifetimes of objects.

<p>
First, note that a thread and the object representing that thread are
different concepts and have different lifetimes.  The thread is a stream of
execution; the thread object is a data structure that represents the
thread.

<p>
A <em>thread</em> finishes executing when it returns from the function that was
specified in the thread constructor.  Soon after the thread finishes executing,
the thread library should deallocate the memory used for the thread's stack
space and context.

<p>
A <em>thread object</em> is destroyed according to the normal rules of
object destruction.  E.g., if the thread object is a local variable of a
block, the thread object is destroyed when that block finishes.
<!--
The thread
object for the thread created by <tt>cpu::init</tt> should never be destroyed.
-->

<p>
The thread object may be destroyed <strong>before or after</strong> the
thread finishes executing, and the destruction of the thread object should
not affect the thread's execution (or vice versa).  If the thread object is
destroyed before the thread finishes executing, the thread should continue
executing.  If the thread finishes executing before the thread object is
destroyed, the memory used for the thread's stack and context should be
deallocated, but the thread object should not be destroyed (e.g., it could
still be used to <tt>join</tt> with the completed thread).

<p>
Second, think about when the constructor for a thread, mutex, or condition
variable may be called.  Threads are <em>not</em> allowed to be constructed
before the system is initialized (i.e., before <tt>cpu::boot</tt> has been
called).  However, mutexes and condition variables <em>are</em> allowed to
be constructed before <tt>cpu::boot</tt> is called (they are often global
variables, which are constructed before <tt>main</tt> is called; see <a
href=<#example">Section 4</a> for an example).  This implies that the
constructors for mutexes and condition variables must not depend on any
cpu or thread library data.  In particular, they should be able to work
without manipulating interrupts.

<h3 id="interrupts">3.4. Interrupts</h3>

<p>
There are two types of interrupts: timer interrupts and inter-processor
interrupts (IPI).  Timer interrupts are generated periodically by the
infrastructure (if they are enabled by <tt>cpu::boot</tt>).
Inter-processor interrupts are received by one CPU when another CPU calls
<tt>cpu::interrupt_send</tt>.  Interrupts can only be received when
interrupts are enabled.  At the time <tt>cpu::init</tt> is called, interrupts
are disabled.

<p>
When a CPU receives an interrupt, the infrastructure consults the
<tt>cpu::interrupt_vector_table</tt> for that CPU and calls the interrupt
handler that is registered for that type of interrupt.  The interrupt
handler begins running with interrupts (still) enabled (if interrupts had
been disabled, the interrupt would not have been received).

<p>
Your thread library is responsible for setting the entries in the interrupt
vector table.  <tt>cpu::interrupt_vector_table[TYPE]</tt> specifies the
address of the function to call when the specified CPU receives interrupt
<tt>TYPE</tt> (<tt>TYPE</tt> can be <tt>cpu::TIMER</tt> or
<tt>cpu::IPI</tt>).

<p>
Remember that interrupts should be disabled only when executing in your thread
library's code.  The code outside your thread library should never execute with
interrupts disabled.

<p>
To help ensure atomicity of multiple operations, your thread library will
manipulate interrupts using functions provided by the <tt>cpu</tt> class.
<tt>interrupt_send</tt> is a normal member function and sends an IPI to the
specified CPU.  <tt>interrupt_disable</tt>, <tt>interrupt_enable</tt>, and
<tt>interrupt_enable_suspend</tt> are <tt>static</tt> member functions;
they affect the CPU that called these functions and are invoked on the
<tt>cpu</tt> class (not on an instance of the <tt>cpu</tt> class).

<ul>

<li><tt>cpu::interrupt_disable</tt> disables interrupts on the executing CPU.

<pre>
    static void interrupt_disable();
</pre>

<li><tt>cpu::interrupt_enable</tt> enables interrupts on the executing CPU.

<pre>
    static void interrupt_enable();
</pre>

<li><tt>cpu::interrupt_enable_suspend</tt> atomically enables interrupts on the
executing CPU and suspends the executing CPU until it receives an
inter-processor interrupt (IPI) from another CPU.

<pre>
    static void interrupt_enable_suspend();
</pre>

<li><tt>cpu::interrupt_send()</tt> sends an inter-processor interrupt to the
specified CPU.

<pre>
    void interrupt_send();
</pre>

</ul>

<h3 id="guard">3.5. Guard variable</h3>

<p>
The infrastructure provides an atomic <tt>guard</tt> variable, which thread
libraries should use to provide mutual exclusion on multiprocessors.
Remember that the switch invariant for multiprocessors specifies that this
guard variable must be <tt>true</tt> when calling <tt>swapcontext</tt>.
guard is initialized to <tt>false</tt>.

<p>
You may use any of the functions in
<a href="http://en.cppreference.com/w/cpp/atomic/atomic"><tt>std::atomic</tt></a>
to manipulate <tt>guard</tt> (e.g., <tt>store</tt>, <tt>exchange</tt>).
The <tt>std::atomic</tt> class doesn't provide a test-and-set function,
but you can easily achieve the same effect with other functions.

<p>
Hint: Beware of using the <tt>load</tt> function--it usually leads to a race
condition.

<h3 id="efficiency">3.6. Efficiency</h3>

<p>
Your thread library should manage the CPUs efficiently.  In particular,
your thread library should minimize busy waiting (though some busy waiting
in the thread library is inevitable when running on a multiprocessor).  In
particular, you should suspend a CPU (using
<tt>cpu::interrupt_enable_suspend</tt>) when there are no runnable threads.

<p>
When all CPUs are suspended, the infrastructure will exit the process
with the message:

<pre>
All CPUs suspended.  Exiting.
</pre>

<!--
Be careful when using static variables in your thread library.  Remember
that <tt>exit()</tt> will call the destructors for these variables, and
this may occur before other program variables (such as threads, mutexes,
and condition variables are destroyed.
-->

<h3 id="schedulingorder">3.7. Scheduling order</h3>

<p>
This section describes the specific scheduling order that your thread
library should follow.  Note that the thread library provided in
<a href="../project1/">Project 1</a> does not guarantee this scheduling
order, since that thread library was provided for developing concurrent
programs (which should work for any scheduling order).

<p>
All scheduling queues should be FIFO.  This includes the ready queue, the queue
of threads waiting for a mutex, the queue of threads waiting on a condition
variable, and the queue of threads waiting for a thread to exit.  All CPUs
should share a single ready queue.  Mutexes should be acquired by threads in
the order in which the mutex was requested (by <tt>mutex::lock</tt> or in
<tt>cv::wait</tt>).

<p>
When a thread creates a thread, unlocks a mutex, or signals/broadcasts a
condition variable, the caller does not yield its CPU.  The created or
unblocked thread should be put on the ready queue and executed when a CPU
becomes available.

<p>
When a thread wakes up in <tt>cv::wait</tt>, it is that thread's
responsibility to request the lock when it next runs.

<h3 id="error">3.8. Error handling</h3>

<p>
Operating system code should be robust.  There are three sources of errors that
OS code should handle.  The first source of errors is
misbehaving user programs.  Your thread library should detect when a user program
misuses thread functions (e.g., a thread releasing a mutex it hasn't locked) and
throw a <tt>std::runtime_error</tt> exception.

<p>
There are certain application behaviors that are arguably errors or not.
Here is a list of questionable behaviors that should <strong>not</strong>
be considered errors: signaling without holding the lock (this is legal
with Mesa monitors); a thread that exits while still holding a mutex (the
mutex can never be unlocked); deadlock (even trivial deadlocks are legal,
such as a thread trying to acquire a mutex it has already locked, or a
thread trying to <tt>join</tt> with itself).  Ask on the forum if you're
unsure whether you should consider a certain behavior an error.

<p>
A second source of error comes from resources that the OS uses, such as
hardware devices.  In this project, the main resource used by the OS is
memory.  If the thread library is unable to service a request due to
lack of memory, it should throw a <tt>std::bad_alloc</tt> exception.
Applications can then catch the exception and proceed accordingly.

<p>
A third source of error is when the OS code itself (in this case, your
thread library) has a bug.  While developing the OS,
the best behavior in this case is for the OS to detect the bug
quickly and assert (this is called a <em>panic</em> in kernel parlance).
These error checks are essential in debugging concurrent programs, because
they help flag error conditions early.  <strong>Use assertion statements
copiously in your thread library to check for bugs in your code (for
reference, 10% of the lines of code in my thread library are
assertions).</strong>

<p>
To make it easier for you to check for errors related to interrupts, the
infrastructure provides two functions, <tt>assert_interrupts_disabled</tt>
and <tt>assert_interrupts_enabled</tt> that your thread library can call to
check that the status of interrupts is as you expect.

<!--
<p>
We will not provide you with an exhaustive list of errors that you should
catch.  OS programmers must have a healthy (?) sense of paranoia to make their
system robust, so part of this assignment is thinking of and handling lots of
errors.  Unfortunately, there will be some errors that are not possible to
handle, because the thread library shares the address space with the user
program and can thus be corrupted by the user program.
-->

<p>
Hint: Autograder test cases 18-20 check how well your thread library
handles errors.

<h3 id="ucontext">3.9. Managing <tt>ucontext</tt> structs</h3>

<p>
Do not initialize a <tt>ucontext</tt> struct by copying another
<tt>ucontext</tt> struct.  Instead, initialize <tt>ucontext</tt> structs
through <tt>getcontext</tt>/<tt>makecontext</tt>, and manage them by
passing or storing pointers to <tt>ucontext</tt> structs, or by
passing/storing pointers to structs that contain a <tt>ucontext</tt> struct
(or by passing/storing pointers to structs that contain a pointer to a
<tt>ucontext</tt> struct, but this is overkill).  The pointers allow
the original <tt>ucontext</tt> struct to never be copied.

<p>
Why is it a bad idea to copy a <tt>ucontext</tt> struct?  The reason is
that you don't know what's in a <tt>ucontext</tt> struct.  Byte-for-byte
copying (e.g., using <tt>memcpy</tt>) can lead to errors unless you know
what's in the struct you're copying.  In the case of a <tt>ucontext</tt>
struct, it happens to contain a pointer to itself (viz. to one of its data
members).  If you copy a <tt>ucontext</tt> using <tt>memcpy</tt>, you will
copy the value of this pointer, and the new copy will point to the
<strong>old</strong> copy's data member.  If you later deallocate the old
copy (e.g., if it was a local variable), then the new copy will point to
garbage.  Copying structs is also a bad idea for performance (the
<tt>ucontext</tt> struct is 348 bytes on Linux/x86).

<p>
Unfortunately, it is rather easy to accidentally copy <tt>ucontext</tt> structs.
Some of the common ways are:
<li>passing a <tt>ucontext</tt> by value into a function
<li>copying the <tt>ucontext</tt> struct into an STL queue
<li>declaring a local <tt>ucontext</tt> variable is almost always a bad idea, since
it practically forces you to copy it

<p>
You should probably use the <tt>new</tt> operator to allocate
<tt>ucontext</tt> structs (or the struct containing a <tt>ucontext</tt>
struct).  If you use an STL class to allocate a <tt>ucontext</tt> struct,
make sure that STL class doesn't move its objects around in memory.  E.g.,
using vector to allocate <tt>ucontext</tt> structs is a bad idea, because
vectors will move memory around when they resize.

<h2 id="example">4. Example application</h2>

<p>
Here is a short program that uses the above thread library, along with the
output generated by the program.  Make sure you understand how the CPU is
switching between two threads while they're executing the <tt>loop</tt>
function.  <tt>i</tt> is on the stack and so is private to each thread.
<tt>g</tt> is a global variable and so is shared among the two threads.

<hr>
<pre>
#include &lt;iostream&gt;
#include &lt;cstdlib&gt;
#include "thread.h"

using namespace std;

int g = 0;

mutex mutex1;
cv cv1;

void loop(void *a)
{
    char *id = (char *) a;
    int i;

    cout << "loop called with id " << id << endl;

    mutex1.lock();
    for (i=0; i<5; i++, g++) {
	cout << id << ":\t" << i << "\t" << g << endl;
        mutex1.unlock();
	thread::yield();
        mutex1.lock();
    }
    cout << id << ":\t" << i << "\t" << g << endl;
    mutex1.unlock();
}

void parent(void *a)
{
    intptr_t arg = (intptr_t) a;

    cout << "parent called with arg " << arg << endl;
    thread t1 ( (thread_startfunc_t) loop, (void *) "child thread");

    loop( (void *) "parent thread");
}

int main()
{
    cpu::boot(1, (thread_startfunc_t) parent, (void *) 100, false, false, 0);
}

<hr>
parent called with arg 100
loop called with id parent thread
parent thread:	0	0
loop called with id child thread
child thread:	0	0
parent thread:	1	1
child thread:	1	2
parent thread:	2	3
child thread:	2	4
parent thread:	3	5
child thread:	3	6
parent thread:	4	7
child thread:	4	8
parent thread:	5	9
child thread:	5	10
All CPUs suspended.  Exiting.
</pre>
<hr>

<h2 id="tips">5. Tips</h2>

<p>
Start by implementing <tt>cpu::init</tt>, <tt>thread::thread</tt>, and
<tt>thread::yield</tt>.  Don't worry at first about atomicity in the thread
library or supporting multiple processors.
After you get that system working, implement the other thread functions.
Next, add calls to <tt>cpu::interrupt_disable</tt> and
<tt>cpu::interrupt_enable</tt> to ensure your library works in the presence of
interrupts.  You'll need to think about what should happen when an
interrupt occurs and how to guarantee atomicity in your thread library
when they occur.  Finally, add support for multiple processors.  Use
the guard variable to ensure atomicity for multiprocessors, and think
about what a CPU should do when there are no runnable threads.

<h2 id="testcases">6. Test cases</h2>

<p>
An integral (and graded) part of writing your thread library will be to write a
suite of test cases to validate any thread library.  This is common practice in
the real world--software companies maintain a suite of test cases for their
programs and use this suite to check the program's correctness after a change.
Writing a comprehensive suite of test cases will deepen your understanding of
how to use and implement threads, and it will help you a lot as you debug your
thread library.

<p>
Each test case for the thread library will be a short C++ program that uses
functions in the thread library (e.g., the example program in
<a href="#example">Section 4</a>).  The name of each test case should
start with <tt>test</tt> and end with <tt>.cc</tt> or <tt>.cpp</tt>, e.g.,
<tt>test1.cc</tt>.

<p>
Each test case should be run without any arguments and should not use any
input files.  Test cases should exit(0) when run with a correct thread
library (normally this will happen when your test case's last runnable
thread ends or blocks).  If you submit your disk scheduler as a test case,
remember to adapt its call to <tt>cpu::boot</tt> and to
specify all inputs (number of requesters, buffers, and the list
of requests) statically in the program.  The list of requests should be
short to make a good test case (i.e., one that you can trace through what
should happen).

<p>
The test cases you submit should call <tt>cpu::boot</tt> with
<tt>num_cpus=1</tt> and without enabling asynchronous or synchronous timer
interrupts.  All buggy thread libraries can be exposed with a single
CPU and without timer interrupts.

<p>
While you cannot submit test cases that use multiple CPUs or enable timer
interrupts, you <strong>should</strong> write and run such test cases
yourself.

<p>
Your test suite may contain up to 22 test cases.  Each test case may generate
at most 10 KB of output and must take less than 60 seconds to run.  These
limits are much larger than needed for full credit.  You will submit your
suite of test cases together with your thread library, and we will grade your
test suite according to how thoroughly it exercises a thread library.
<a href="#grading">Section 9</a> describes how your test suite will be graded.

<h2 id="pimpl">7. Opaque pointers</h2>

<p>
You may not modify or rename the header files included in this handout.
However, you will probably need to add data and functions for the
classes declared in the headers (<tt>cpu</tt>, <tt>thread</tt>,
<tt>mutex</tt>, <tt>cv</tt>).  We use the <em>opaque pointer</em> idiom
(sometimes called <em>Pimpl</em>, for "pointer to implementation") to allow
you to add data/functions for a class without changing that class's header
file.

<p>
The <tt>cpu</tt>, <tt>thread</tt>, <tt>mutex</tt>, <tt>cv</tt> classes each
provide an <tt>impl_ptr</tt> member, which points to a class
<tt>impl</tt>.  For example, class <tt>thread</tt> provides
<tt>thread::impl_ptr</tt>, which points to an instance of
class <tt>thread::impl</tt>.

<p>
You may define each <tt>impl</tt> class and use each <tt>impl_ptr</tt>
however you like.  For example, you can store custom data and
functions you need for a <tt>mutex</tt> in an instance of
the <tt>mutex::impl</tt> class, then point to this instance via
a mutex's <tt>impl_ptr</tt>.

<p>
Typically, a class constructor will allocate the <tt>impl</tt> object and
initialize the <tt>impl_ptr</tt> to point to the allocated data.
For the <tt>cpu</tt> class, you can do these tasks in <tt>cpu::init</tt>,
since you're not writing the <tt>cpu</tt> class constructor.

<h2 id="logistics">8. Project logistics</h2>

<p>
Write your thread library in C++ on Linux.  The internal functions and
global variables in your thread library should be declared <tt>static</tt>
to prevent naming conflicts with programs that link with your thread
library.

<p>
Use <tt>g++ 4.8.2</tt> to compile your programs.  To use <tt>g++ 4.8.2</tt>
on CAEN computers, put the following command in your startup file (e.g.,
<tt>~/.profile</tt>):

<pre>
module load gcc
module load gdb/7.5.1
</pre>

<!--
<p>
You should also set the <tt>LD_BIND_NOW</tt> environment variable to 1.
This works around an apparent incompatibility between the thread library
and the Linux dynamic linker.  Add the following line to your 
<tt>~/.profile</tt>:

<pre>
export LD_BIND_NOW=1
</pre>
-->

<p>
You may use any functions included in the standard C++ library, including
the STL.  You should not use any libraries other than the standard C++
library.  To compile an application program (e.g., <tt>app.cc</tt>)
with your thread library (e.g., <tt>thread.cc</tt>), run:

<pre>
g++ thread.cc app.cc libcpu.a -ldl -pthread -std=c++11
</pre>

<p>
You may add options <tt>-g</tt> and <tt>-Wall</tt> for debugging and
<tt>-o</tt> to name the executable.

<p>
Your thread library code may be in multiple files.
Each file name must end with <tt>.cc</tt>, <tt>.cpp</tt>, or <tt>.h</tt>
and must not start with <tt>test</tt>.

<p>
We have created a private <a href="https://github.com/eecs482">github</a>
repository for your group
(<tt>eecs482/&ltgroup&gt.2</tt>), where <tt>&ltgroup&gt</tt> is
the sorted, dot-separated list of your group members' uniqnames.  Initialize
your local repository by cloning the (empty) repository from github, e.g.,

<pre>
git clone git@github.com:eecs482/uniqnameA.uniqnameB.2
</pre>

<h2 id="grading">9. Grading, auto-grading, and formatting</h2>

<p>
To help you validate your programs, your submissions will be graded
automatically, and the results will be provided to you.  You may then
continue to work on the project and re-submit.  The results from the
auto-grader will not be very illuminating; they won't tell you where your
problem is or give you the test programs.  The main purpose of the
auto-grader is to help you know to keep working on your project (rather
than thinking it's perfect and ending up with a 0).  The best way to debug
your program is to generate your own test cases, figure out the correct
answers, and compare your program's output to the correct answers.  This is
also one of the best ways to learn the concepts in the project.

<p>
The student suite of test cases will be graded according to how thoroughly
they test a thread library.  We will judge thoroughness of the test suite
by how well it exposes potential bugs in a thread library.  The auto-grader
will first compile a test case with a correct thread library and generate
the correct output (on <tt>stdout</tt>, i.e., the stream used by
<tt>cout</tt>) for this test case.  Test cases should not cause any compile
or run-time errors when compiled with a correct thread library.  The
auto-grader will then compile the test case with a set of buggy thread
libraries.  A test case exposes a buggy thread library by causing it to
generate output (on <tt>stdout</tt>) that differs from the correct output.
The test suite is graded based on how many of the buggy thread libraries
were exposed by at least one test case.  This is known as <em>mutation
testing</em> in the research literature on automated testing.

<p>
You may submit your program as many times as you like.  However, only the
feedback from the first submission of each day will be provided to you.
Later submissions on that day will be graded and cataloged, but the results
will not be provided to you.  See the
<a href=http://www.eecs.umich.edu/~pmchen/eecs482/faq.html#limit>FAQ</a>
for why we use this policy.

<p>
In addition to this one-per-day policy, you will be given 3 bonus submissions
that also provide feedback.  These will be used automatically--any submission
you make after the first one of that day will use one of your bonus
submissions.  After your 3 bonus submissions are used up, the system will
continue to provide 1 feedback per day.

<p>
Because you are writing concurrent programs, the auto-grader may return
non-deterministic results.  In particular, test cases 24 and 27-40
use multiprocessors
or asynchronous timer interrupts and are therefore non-deterministic.

<p>
Because your programs will be auto-graded, you must be careful to follow the
exact rules in the project description.  In particular:

<li>Your thread library should not generate any output.  Only the program
using your thread library should generate output.

<li>Do not modify or rename the header files included in this handout.

<p>
In addition to the auto-grader's evaluation of your program's correctness, a
human grader will evaluate your program on issues such as the clarity and
completeness of your documentation, coding style, the efficiency, brevity, and
understandability of your code, etc..  Your final score will be the product of
the hand-graded score (between 1-1.12) and the auto-grader score.

<h2 id="submission">10. Turning in the project</h2>

<p>
<a href=../submit.php?2>Submit</a> the following files for your thread library:

<ul>
<li>C++ files for your thread library.  File names should end in
<tt>.cc</tt>, <tt>.cpp</tt>, or <tt>.h</tt> and must not start with
<tt>test</tt>.  Do not submit the files provided in this handout.

<li>Suite of test cases.  Each test case should be in a single file.  File
names should start with <tt>test</tt> and end with <tt>.cc</tt> or
<tt>.cpp</tt>.

</ul>

<p>
Each person should also describe the contributions of each team member
using the following <a href="../peer.php?peer2">web form</a>.

<p>
The official time of submission for your project will be the time of your
last submission.  Submissions after the due date
will automatically use up your late days; if you have no late days left,
late submissions will not be counted.

<h2 id="files">11. Files included in this handout</h2>

<ul>
<li><a href=cpu.h><tt>cpu.h</tt></a>
<li><a href=cv.h><tt>cv.h</tt></a>
<li><a href=libcpu.a><tt>libcpu.a</tt></a>
<li><a href=mutex.h><tt>mutex.h</tt></a>
<li><a href=thread.h><tt>thread.h</tt></a>
</ul>

</body>
</html>
